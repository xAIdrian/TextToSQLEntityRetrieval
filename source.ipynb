{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /Users/millionairemacmillionairemac/.local/lib/python3.11/site-packages (4.45.2)\n",
      "Requirement already satisfied: torch in /Users/millionairemacmillionairemac/.local/lib/python3.11/site-packages (2.2.2)\n",
      "Requirement already satisfied: pandas in /Users/millionairemacmillionairemac/.local/lib/python3.11/site-packages (2.2.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch pandas\n",
    "!pip install sentencepiece\n",
    "!pip install scikit-learn\n",
    "# needed for training\n",
    "! pip install -U accelerate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  entity_name                   field_name field_type  \\\n",
      "0         CDR      ifc.ootb.CDR.callStatus     string   \n",
      "1         CDR             ifc.CDR.caseCode     string   \n",
      "2         CDR            ifc.CDR.chatTopic     string   \n",
      "3         CDR  ifc.ootb.CDR.createDateTime       date   \n",
      "4         CDR       ifc.ootb.CDR.direction     string   \n",
      "\n",
      "                                         description  \n",
      "0  Status of the call: \"Successful\", \"Failed\", \"B...  \n",
      "1            Unique code identifying a specific case  \n",
      "2         Topic or subject of discussion in the chat  \n",
      "3                  Date and time of record creation.  \n",
      "4         Direction of the call (incoming, outgoing)  \n",
      "                                            question  \\\n",
      "0           Find all calls made using 3G technology.   \n",
      "1  List all Reddit comments posted yesterday with...   \n",
      "2  Show me investigations that are either open or...   \n",
      "3  Find all insights related to the witness Jane ...   \n",
      "4  List all web activities updated in the last da...   \n",
      "\n",
      "                                                json  \n",
      "0  {'entityType': 'CDR', 'statements': [{'type': ...  \n",
      "1  {'entityType': 'Web Activity', 'statements': [...  \n",
      "2  {'entityType': 'Investigation', 'statements': ...  \n",
      "3  {'entityType': 'Insight', 'statements': [{'typ...  \n",
      "4  {'entityType': 'Web Activity', 'statements': [...  \n",
      "test sample mapping\n",
      "[{'field_name': 'ifc.ootb.Participant.isSuspicious', 'description': 'Boolean auto-generated Indicator showing if the identifier was defined as suspicious by the users or is it a SIM-Swapper (defined by the platform)'}, {'field_name': 'ifc.ootb.Participant.targetName', 'description': 'this is target based SIGINT - (local police level) (unlike mass sigint in country level). Name of target like Yossi cohen'}, {'field_name': 'ifc.ootb.Phone.IMEI', 'description': 'International Mobile Equipment Identity of the phone. It is a unique 15-digit code. Each IMEI number is unique to a device and does not change, even if the SIM card is changed'}, {'field_name': 'ifc.ootb.Phone.IMSI', 'description': 'IMSI stands for International Mobile Subscriber Identity. It is a unique number associated with all cellular networks. It is used to identify the user of a cellular network and is a key part of any mobile network. The IMSI is stored on a SIM card and consists of up to 15 digits.The structure of the IMSI is as follows:Mobile Country Code (MCC): The first three digits represent the country code, identifying the country in which the carrier operates.Mobile Network Code (MNC): The next two or three digits identify the mobile network within the country.Mobile Subscriber Identification Number (MSIN): The remainder of the IMSI is a unique identifier for the subscriber within the network.'}, {'field_name': 'ifc.ootb.Phone.MSISDN', 'description': \"MSISDN or phone number is the phone number associated with a mobile network subscriber. It is the globally unique number that identifies a subscriber's subscription in a mobile network, allowing them to make and receive calls, send and receive SMS, and utilize mobile data.Purpose: The primary purpose of an MSISDN is to identify the subscriber's phone number for routing calls and messages. It is tied to the SIM card (Subscriber Identity Module) used in the mobile device.Components: An MSISDN includes the country code (CC), the national destination code (NDC), and the subscriber number (SN).\"}, {'field_name': 'ifc.ootb.Phone.title', 'description': 'Title or label associated with the phone (to display on system)'}, {'field_name': 'ifc.ootb.Participant.tlidDominantLanguage', 'description': 'Dominant language for the Telecommunications Interception Directive'}, {'field_name': 'ifc.ootb.Participant.aliasName', 'description': 'Alias name of the participant'}, {'field_name': 'ifc.ootb.Participant.firstActiveDate', 'description': 'Date when the participant was first active on SIGINT'}, {'field_name': 'ifc.ootb.Participant.lastActiveDate', 'description': 'Date when the participant was last active on SIGINT'}, {'field_name': 'ifc.Phone.accessCallingNumber', 'description': 'Calling number used to access the phone'}, {'field_name': 'ifc.ootb.Participant.deviceName', 'description': 'Name of the device used by the participant'}, {'field_name': 'ifc.ootb.Participant.isTarget', 'description': 'Indicates whether the identifier defined as a target, meaning content is visible (Under a court order)'}, {'field_name': 'ifc.Phone.type', 'description': 'Type of phone (either foreign, mobile, or landline)'}, {'field_name': 'ifc.ootb.Phone.IMSI.objectID', 'description': \"Object ID associated with the phone's IMSI\"}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/z10gkxp14_vbcbgjmpzd69200000gn/T/ipykernel_13093/2222115628.py:14: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  entity_to_field_mapping = fields_desc.groupby('entity_name').apply(lambda x: x[['field_name', 'description']].to_dict(orient='records')).to_dict()\n"
     ]
    }
   ],
   "source": [
    "# load data and create mapping into new dataframe\n",
    "# right now we are just using the user query \n",
    "### TODO files are static paths now.  we need to make them dynamic and maybe add a nice UI to select the file\n",
    "import pandas as pd\n",
    "\n",
    "fields_desc = pd.read_csv('fields_description.csv')\n",
    "user_queries = pd.read_csv('user_queries.csv')\n",
    "\n",
    "print(fields_desc.head())\n",
    "print(user_queries.head())\n",
    "\n",
    "# Create a dictionary mapping entity names to their field descriptions and properties\n",
    "# This groups the data by entity_name and creates a nested dictionary structure for easy access to field information for each entity type\n",
    "entity_to_field_mapping = fields_desc.groupby('entity_name').apply(lambda x: x[['field_name', 'description']].to_dict(orient='records')).to_dict()\n",
    "\n",
    "print('test sample mapping')\n",
    "print(entity_to_field_mapping.get('Phone', []))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error decoding JSON for query: Which phones have been marked as suspicious?\n",
      "Error: Expecting value: line 1 column 150 (char 149)\n",
      "Error decoding JSON for query: What failed call attempts were made from target phones to numbers containing '1234'?\n",
      "Error: Expecting value: line 1 column 228 (char 227)\n",
      "Error decoding JSON for query: Which phones are set on Arabic and are marked as suspicious?\n",
      "Error: Expecting value: line 1 column 280 (char 279)\n",
      "Error decoding JSON for query: List emails sent to phones associated with the target Sarah Johnson\n",
      "Error: Expecting value: line 1 column 337 (char 336)\n",
      "Error decoding JSON for query: List all emails from john@company.com to jane@company.com with attachments in February 2024\n",
      "Error: Expecting value: line 1 column 646 (char 645)\n",
      "Error decoding JSON for query: Show me any insights related to the interview with the victim's family yesterday.\n",
      "Error: Expecting ',' delimiter: line 1 column 152 (char 151)\n",
      "Error decoding JSON for query: Find all emails about 'meeting' sent between john@example.com and target phones last week\n",
      "Error: Expecting value: line 1 column 774 (char 773)\n",
      "Error decoding JSON for query: What calls from target phones to 0542164185 used UMTS protocol in the last 48 hours?\n",
      "Error: Expecting value: line 1 column 228 (char 227)\n",
      "Error decoding JSON for query: Find all CDRs of 0527893156 or 0523741852 with attachments in the past 48 hours\n",
      "Error: Expecting value: line 1 column 303 (char 302)\n",
      "Error decoding JSON for query: Show calls woth duartion of 30 minutes from target phones to numbers starting with '+1'.\n",
      "Error: Expecting value: line 1 column 228 (char 227)\n",
      "Error decoding JSON for query: List all communications initiated by phones with MSISDN +972541234567 to any target phone\n",
      "Error: Expecting value: line 1 column 380 (char 379)\n",
      "Error decoding JSON for query: Give me information about phones with alias name 'John's iPhone' or 'Mary's Samsung'\n",
      "Error: Expecting ',' delimiter: line 1 column 228 (char 227)\n",
      "Error decoding JSON for query: Show me any emails sent from jane@company.com to ariel042cohen@gmail.com with attachments in the past 2 weeks\n",
      "Error: Expecting value: line 1 column 678 (char 677)\n",
      "Error decoding JSON for query: Show me SMS messages exchanged from target phones to the number 0542164185 in the last 90 days\n",
      "Error: Expecting value: line 1 column 228 (char 227)\n",
      "Error decoding JSON for query: Show calls that had content from phones marked as suspicious to 0542164185.\n",
      "Error: Expecting value: line 1 column 232 (char 231)\n",
      "Error decoding JSON for query: Retrieve the details of suspicious phones with IMEI 356938035643809 or 490154203237518\n",
      "Error: Expecting value: line 1 column 150 (char 149)\n",
      "Error decoding JSON for query: Find all emails with 'secret' in the subject sent from spy@agency.gov to target phones\n",
      "Error: Expecting value: line 1 column 614 (char 613)\n",
      "Error decoding JSON for query: Show classified SMS conversations of 0527654321 in the first week of January 2024\n",
      "Error: Expecting value: line 1 column 239 (char 238)\n",
      "Error decoding JSON for query: Show me all calls made by target phones to +972501234567\n",
      "Error: Expecting value: line 1 column 487 (char 486)\n",
      "Error decoding JSON for query: Find all high priority visa requests submitted since 1 January 2024\n",
      "Error: Expecting value: line 1 column 150 (char 149)\n",
      "Error decoding JSON for query: Find all calls made using 3G technology from 0542164185 to target phones in the last month\n",
      "Error: Expecting value: line 1 column 749 (char 748)\n",
      "Error decoding JSON for query: List all classified emails with attachments sent to jane@company.com last month\n",
      "Error: Expecting value: line 1 column 398 (char 397)\n",
      "Error decoding JSON for query: Show me all sms sent from suspicious phones to the number 0542164185 in the last week.\n",
      "Error: Expecting value: line 1 column 232 (char 231)\n",
      "Error decoding JSON for query: What sms were sent from target phones to numbers starting with '052'?\n",
      "Error: Expecting value: line 1 column 228 (char 227)\n",
      "Error decoding JSON for query: Find all successful calls made from suspicious phones to 0542164185 in 2022.\n",
      "Error: Expecting value: line 1 column 698 (char 697)\n",
      "Error decoding JSON for query: List suspicious phones active within the last 2 weeks.\n",
      "Error: Expecting value: line 1 column 150 (char 149)\n",
      "Error decoding JSON for query: What calls 30 minutes long were made from suspicious phones to 0549112233?\n",
      "Error: Expecting value: line 1 column 232 (char 231)\n",
      "Error decoding JSON for query: Which suspicious phone had sent calls?\n",
      "Error: Expecting value: line 1 column 132 (char 131)\n",
      "Error decoding JSON for query: What calls were made from target phones using 3g or 4g?\n",
      "Error: Expecting value: line 1 column 333 (char 332)\n",
      "Error decoding JSON for query: Show me communication incoming records of the target phones with alias name starting with 'Agent'.\n",
      "Error: Expecting value: line 1 column 266 (char 265)\n",
      "Error decoding JSON for query: Show emails sent from devices marked as suspicious to mail ending with '@company.com'.\n",
      "Error: Expecting value: line 1 column 232 (char 231)\n",
      "Error decoding JSON for query: List the suspicious phones that communicated with +972559876543 in February 2024\n",
      "Error: Expecting value: line 1 column 132 (char 131)\n",
      "Error decoding JSON for query: Find all emails sent from johndoe@gmail.com using phones marked as suspicious\n",
      "Error: Expecting value: line 1 column 472 (char 471)\n",
      "Error decoding JSON for query: Find all calls to suspicious phones in the past 3 months.\n",
      "Error: Expecting value: line 1 column 495 (char 494)\n",
      "Error decoding JSON for query: Find all SMS messages containing the word 'meeting' sent from 0549876543 to target phones in the past week\n",
      "Error: Expecting value: line 1 column 751 (char 750)\n",
      "Error decoding JSON for query: Show me the suspicious phones that made calls to +1-555-987-6543.\n",
      "Error: Expecting value: line 1 column 132 (char 131)\n",
      "Error decoding JSON for query: Find emails with attachments sent from phones associated with alias name 'John' to johndoe@gmail.com.\n",
      "Error: Expecting value: line 1 column 258 (char 257)\n",
      "Error decoding JSON for query: Retrieve all emails with attachments sent from john@company.com since 1 March 2024.\n",
      "Error: Expecting value: line 1 column 359 (char 358)\n",
      "Error decoding JSON for query: Show me all emails with attachments sent to bob@company.com today\n",
      "Error: Expecting value: line 1 column 539 (char 538)\n",
      "Error decoding JSON for query: Show me all emails with PDF attachments sent in the first half of October 2024.\n",
      "Error: Expecting value: line 1 column 377 (char 376)\n",
      "Error decoding JSON for query: Show me all classified communications in the past 30 days\n",
      "Error: Expecting value: line 1 column 135 (char 134)\n",
      "Error decoding JSON for query: Show me sms sent from target phones to  0501234567\n",
      "Error: Expecting value: line 1 column 483 (char 482)\n",
      "Error decoding JSON for query: Show emails to dani@gmail.com that have PDF attachments.\n",
      "Error: Expecting value: line 1 column 273 (char 272)\n",
      "Error decoding JSON for query: Which phones have the alias name 'John's work phone'?\n",
      "Error: Expecting ',' delimiter: line 1 column 153 (char 152)\n",
      "Error decoding JSON for query: Find all suspicious phones\n",
      "Error: Expecting value: line 1 column 150 (char 149)\n",
      "Error decoding JSON for query: Show me sms sent from a target phone to 0542164185\n",
      "Error: Expecting value: line 1 column 483 (char 482)\n",
      "Error decoding JSON for query: Display voice calls lasting 30 minutes to non-target phones\n",
      "Error: Expecting value: line 1 column 437 (char 436)\n",
      "Error decoding JSON for query: Show sms sent on 2023-02-14 from phones with imei 123456789012345 to target phones\n",
      "Error: Expecting value: line 1 column 558 (char 557)\n",
      "Error decoding JSON for query: Find SMS messages containing the word 'meeting' sent from target phones to the number 0526357106.\n",
      "Error: Expecting value: line 1 column 228 (char 227)\n",
      "Error decoding JSON for query: What SMS messages were sent from suspicious phones to 0549876543 containing the word 'urgent'?\n",
      "Error: Expecting value: line 1 column 598 (char 597)\n",
      "Error decoding JSON for query: Show all phones labeled as suspicious.\n",
      "Error: Expecting value: line 1 column 150 (char 149)\n",
      "Error decoding JSON for query: List emails with attachments sent from ariel042cohen@gmail.com.\n",
      "Error: Expecting value: line 1 column 281 (char 280)\n"
     ]
    }
   ],
   "source": [
    "# prepare our data for training. we combine our user query with field description\n",
    "import json\n",
    "import re\n",
    "\n",
    "def clean_json_string(json_string):\n",
    "    # Remove any leading/trailing whitespace\n",
    "    json_string = json_string.strip()\n",
    "    \n",
    "    # Ensure the string is enclosed in curly braces\n",
    "    if not json_string.startswith('{'):\n",
    "        json_string = '{' + json_string\n",
    "    if not json_string.endswith('}'):\n",
    "        json_string = json_string + '}'\n",
    "    \n",
    "    # Replace single quotes with double quotes, but not within values\n",
    "    json_string = re.sub(r\"(?<!\\\\)'\", '\"', json_string)\n",
    "    \n",
    "    # Remove any trailing commas before closing braces or brackets\n",
    "    json_string = re.sub(r',\\s*([\\]}])', r'\\1', json_string)\n",
    "    \n",
    "    return json_string\n",
    "\n",
    "def prepare_data_for_training(user_query, fields_mapping):\n",
    "    inputs, labels = [], []\n",
    "\n",
    "    for _, row in user_queries.iterrows():\n",
    "        query = row['question']\n",
    "        cleaned_json_string = clean_json_string(row['json'])\n",
    "        \n",
    "        try:\n",
    "            json_data = json.loads(cleaned_json_string)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON for query: {query}\")\n",
    "            print(f\"Error: {e}\")\n",
    "            continue  # Skip this row and continue with the next one\n",
    "        \n",
    "        # extract entity types and relation target types\n",
    "        entity_type = json_data.get('entityType', '')\n",
    "        relation_type = json_data.get('relationTargetType', '')\n",
    "\n",
    "        # get the description for each entity type\n",
    "        fields = fields_mapping.get(entity_type, [])\n",
    "        field_descriptions = ';'.join([f\"{field['field_name']}: {field['description']}\" for field in fields])\n",
    "\n",
    "        #combine query with descriptions\n",
    "        input_text = f\"Query: {query}. Entity: {entity_type}. Fields: {field_descriptions}\"\n",
    "        inputs.append(input_text)\n",
    "        labels.append(entity_type if not relation_type else f\"{entity_type}|{relation_type}\")\n",
    "\n",
    "    return inputs, labels\n",
    "\n",
    "# prepare data\n",
    "inputs, labels = prepare_data_for_training(user_queries, entity_to_field_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input 1: Query: Find all calls made using 3G technology.. Entity: CDR. Fields: ifc.ootb.CDR.callStatus: Status of the call: \"Successful\", \"Failed\", \"Blocked\", or \"Redirected\";ifc.CDR.caseCode: Unique code identifying a specific case;ifc.CDR.chatTopic: Topic or subject of discussion in the chat;ifc.ootb.CDR.createDateTime: Date and time of record creation.;ifc.ootb.CDR.direction: Direction of the call (incoming, outgoing);ifc.ootb.CDR.duration: Duration of the communication in minutes. You can ask it For example: 1min -> 60;ifc.CDR.emailSubject: Subject of the email communication;ifc.ootb.CDR.endTime: Time when the communication ended;ifc.ootb.CDR.hasContent: Indicates if the communication has content;ifc.ootb.CDR.imei: this field is intended to store the IMEI number of the device who made a call.;ifc.ootb.CDR.imei2: this field is intended to store the IMEI number of the device that is receiving the call. It serves the same purposes as the caller's IMEI but for the receiving side of the communication.;ifc.ootb.CDR.imsi: The IMSI that initiate the call as a sender. IMSI stands for International Mobile Subscriber Identity. It is a unique number associated with all cellular networks. It is used to identify the user of a cellular network and is a key part of any mobile network. The IMSI is stored on a SIM card and consists of up to 15 digits.The structure of the IMSI is as follows:Mobile Country Code (MCC): The first three digits represent the country code, identifying the country in which the carrier operates.Mobile Network Code (MNC): The next two or three digits identify the mobile network within the country.Mobile Subscriber Identification Number (MSIN): The remainder of the IMSI is a unique identifier for the subscriber within the network.;ifc.ootb.CDR.imsi2: The IMSI that received the call as a receiver. IMSI is an International Mobile Subscriber Identity (IMSI) is a 15-digit number for every user in a Global System for Mobile communication (GSM). The IMSI is used by Mobile Network Operators (MNOs) and is an important part of the Subscriber Identity Module (SIM) profile.;ifc.CDR.interceptionCriteria: Criteria for intercepting the communication;ifc.CDR.interceptionFilter: Filter applied for interception;ifc.ootb.CDR.ipAddress: IP address of the communication's  Origin ;ifc.ootb.CDR.isAttachment: Indicates if the communication has an attachment;ifc.CDR.isClassified: Indicates if the communication is classified;ifc.ootb.CDR.msisdn: MSISDN or phone number is the phone number associated with a mobile network subscriber as a sender. It is the globally unique number that identifies a subscriber's subscription in a mobile network, allowing them to make calls, send SMS, and utilize mobile data as sender.Purpose: The primary purpose of an MSISDN is to identify the subscriber's phone number for routing calls and messages. It is tied to the SIM card (Subscriber Identity Module) used in the mobile device.Components: An MSISDN includes the country code (CC), the national destination code (NDC), and the subscriber number (SN).;ifc.ootb.CDR.msisdn2: MSISDN or phone number is the phone number associated with a mobile network subscriber as a receiver. It is the globally unique number that identifies a subscriber's subscription in a mobile network, allowing them to receive calls, receive SMS, and utilize mobile data as reciever.Purpose: The primary purpose of an MSISDN is to identify the subscriber's phone number for routing calls and messages. It is tied to the SIM card (Subscriber Identity Module) used in the mobile device.Components: An MSISDN includes the country code (CC), the national destination code (NDC), and the subscriber number (SN).;ifc.ootb.CDR.protocol: Communication protocol used like GSM or UMTS;ifc.ootb.CDR.provider: Provider of the network service;ifc.ootb.CDR.smsProtocol: Protocol used for SMS communication;ifc.ootb.CDR.smsText: Text content of the SMS;ifc.ootb.CDR.smsType: Type of the SMS (e.g., text, binary);ifc.ootb.CDR.startTime: Time when the communication started;ifc.CDR.subcaseCode: Code for the subcase of a known case. Identify between this field and the ifc.CDR.caseCode;ifc.CDR.targetCode: Code identifying the target of the communication;ifc.ootb.CDR.technology: Technology used in the communication, either: 2G,3G,4G,5G,other, WiFi;ifc.ootb.CDR.type: Type of the communication, either: None-Call, Text,Voice, VoiceEdited, Web or Email. Text type is SMS, Voice type is Phone Calls;ifc.ootb.CDR.mainLanguage: Primary language of the communication content;ifc.ootb.CDR.ipAddress2: IP address of the communication's  Destination;ifc.ootb.CDR.originatorEmailAddress: Email address of the sender;ifc.ootb.CDR.destinationEmailAddress: Email address of the recipient;ifc.ootb.CDR.orignatorNetworkName: Name of the originator's network;ifc.ootb.CDR.destinatorNetworkName: Name of the recipient's network\n",
      "Label 1: CDR\n",
      "Input 2: Query: List all Reddit comments posted yesterday with a negative sentiment. Entity: Web Activity. Fields: ifc.ootb.Orbis.platform: the social network name form which the actor was collected (e.g. facebook instagram linkedin etc. );ifc.ootb.WebActivity.writerFullName: Full name of the writer who wrote the post;ifc.ootb.WebActivity.writerUri: URI of the writers profile or content;ifc.ootb.Orbis.updateDate: Date when the post was updated;ifc.ootb.Orbis.collectDate: Date when the post data was collected;ifc.ootb.Orbis.publishDate: Date when the post was published or created;ifc.ootb.WebActivity.numberOfLikes: Number of likes on the activity;ifc.ootb.WebActivity.numberShares: Number of times the activity was shared;ifc.ootb.WebActivity.numberActivities: Count of all web activities (e.g. posts, reshares) nested under this web activity;ifc.ootb.WebActivity.numberTags: Number of tags associated with the activity;ifc.ootb.WebActivity.mainLanguage: Main language of the activity;ifc.ootb.WebActivity.sentiment: sentiment of the text with the web activity (can be positive or negative);ifc.ootb.WebActivity.sentimentScore: a score between 0 (low) and 1 (high) of the sentiment analysis certainty of the text of the activity;ifc.ootb.WebActivity.text: Text content of the web activity;ifc.ootb.Orbis.creditCard: NER extraction of entities representing credit card information as extracted from ORBIS;ifc.ootb.Orbis.email: NER extraction of entities representing emails as extracted from ORBIS;ifc.ootb.Orbis.hashtags: Hashtags mentioned in the activity text;ifc.ootb.Orbis.ipAddress: IP address mentioned in the activity text;ifc.ootb.Orbis.mentions: a mention of a profile in social media usually with an @ sign;ifc.ootb.Orbis.nationality: Nationality mentioned in the activity text;ifc.ootb.Orbis.phone: Phone number mentioned in the activity text;ifc.ootb.Orbis.religion: Religions mentioned in the activity text;ifc.ootb.Orbis.url: URL mentioned in the activity text;ifc.ootb.Orbis.landmarks: names of landmarks found in the activity (e.g eiffel tower);ifc.ootb.WebActivity.title: Title of the web activity\n",
      "Label 2: Web Activity\n",
      "Input 3: Query: Show me investigations that are either open or were created in the last 3 months. Entity: Investigation. Fields: ifc.core.description: Detailed summary of the investigation;ifc.core.dueTime: Scheduled completion time for the investigation;ifc.core.state: Current state of the investigation. either \"open\" or \"close\";ifc.core.priority: Priority level of the investigation: \"regular\", \"medium\" or \"high\" in ascending order;ifc.core.createtime: Creation time of the investigation record\n",
      "Label 3: Investigation\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(f\"Input {i+1}: {inputs[i]}\")\n",
    "    print(f\"Label {i+1}: {labels[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: 553, Validation size: 139\n"
     ]
    }
   ],
   "source": [
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_inputs, val_inputs, train_labels, val_labels = train_test_split(\n",
    "    inputs, labels, test_size=0.2, stratify=labels, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training size: {len(train_inputs)}, Validation size: {len(val_inputs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AlbertTokenizer\n",
    "import torch\n",
    "\n",
    "model_name = \"twmkn9/albert-base-v2-squad2\"\n",
    "tokenizer = AlbertTokenizer.from_pretrained(model_name)\n",
    "train_encodings = tokenizer(train_inputs, truncation=True, padding=True, return_tensors=\"pt\")\n",
    "val_encodings = tokenizer(val_inputs, truncation=True, padding=True, return_tensors=\"pt\")\n",
    "\n",
    "# labels to tensors. we can't have names only machine values\n",
    "# remove duplicates and iterate through to assign a number\n",
    "unique_labels = list(set(labels))\n",
    "train_labels_tensor = torch.tensor([unique_labels.index(lbl) for lbl in train_labels])\n",
    "val_labels_tensor = torch.tensor([unique_labels.index(lbl) for lbl in val_labels])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training encodings: torch.Size([553, 512]), Labels: torch.Size([553])\n",
      "Validation encodings: torch.Size([139, 512]), Labels: torch.Size([139])\n"
     ]
    }
   ],
   "source": [
    "# do our dimensions match?\n",
    "print(f\"Training encodings: {train_encodings['input_ids'].shape}, Labels: {train_labels_tensor.shape}\")\n",
    "print(f\"Validation encodings: {val_encodings['input_ids'].shape}, Labels: {val_labels_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare results folder\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Create a unique output directory\n",
    "base_output_dir = \"./results\"\n",
    "current_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_dir = os.path.join(base_output_dir, f\"run_{current_time}\")\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at twmkn9/albert-base-v2-squad2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/millionairemacmillionairemac/.local/lib/python3.11/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 24\u001b[0m\n\u001b[1;32m      6\u001b[0m model \u001b[38;5;241m=\u001b[39m AlbertForSequenceClassification\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n\u001b[1;32m      8\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m      9\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39moutput_dir,\n\u001b[1;32m     10\u001b[0m     evaluation_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m     weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m,\n\u001b[1;32m     16\u001b[0m )\n\u001b[1;32m     18\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     19\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     20\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m     21\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m: train_encodings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     23\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m: train_encodings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m---> 24\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mtrain_labels_tensor\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m    \n\u001b[1;32m     25\u001b[0m     },\n\u001b[1;32m     26\u001b[0m     eval_dataset\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m: val_encodings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     28\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m: val_encodings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m: val_labels_tensor[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     30\u001b[0m     },\n\u001b[1;32m     31\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer,\n\u001b[1;32m     32\u001b[0m )\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 1"
     ]
    }
   ],
   "source": [
    "# model and training run\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import AlbertForSequenceClassification\n",
    "import torch\n",
    "\n",
    "model = AlbertForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset={\n",
    "        'input_ids': train_encodings['input_ids'],\n",
    "        'attention_mask': train_encodings['attention_mask'],\n",
    "        'labels': train_labels_tensor['input_ids']    \n",
    "    },\n",
    "    eval_dataset={\n",
    "        'input_ids': val_encodings['input_ids'],\n",
    "        'attention_mask': val_encodings['attention_mask'],\n",
    "        'labels': val_labels_tensor['input_ids']\n",
    "    },\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlbertForQuestionAnswering(\n",
      "  (albert): AlbertModel(\n",
      "    (embeddings): AlbertEmbeddings(\n",
      "      (word_embeddings): Embedding(30000, 128, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 128)\n",
      "      (token_type_embeddings): Embedding(2, 128)\n",
      "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0, inplace=False)\n",
      "    )\n",
      "    (encoder): AlbertTransformer(\n",
      "      (embedding_hidden_mapping_in): Linear(in_features=128, out_features=768, bias=True)\n",
      "      (albert_layer_groups): ModuleList(\n",
      "        (0): AlbertLayerGroup(\n",
      "          (albert_layers): ModuleList(\n",
      "            (0): AlbertLayer(\n",
      "              (full_layer_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (attention): AlbertSdpaAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (attention_dropout): Dropout(p=0, inplace=False)\n",
      "                (output_dropout): Dropout(p=0, inplace=False)\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              )\n",
      "              (ffn): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (ffn_output): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (activation): NewGELUActivation()\n",
      "              (dropout): Dropout(p=0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "`AcceleratorState` object has no attribute `distributed_type`. This happens if `AcceleratorState._reset_state()` was called and an `Accelerator` or `PartialState` was not reinitialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# running the big boy\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/trainer.py:2052\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2050\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2051\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2052\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2053\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2054\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2055\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2056\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2057\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/trainer.py:2081\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2079\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrently training with a batch size of: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2080\u001b[0m \u001b[38;5;66;03m# Data loader and number of training steps\u001b[39;00m\n\u001b[0;32m-> 2081\u001b[0m train_dataloader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_train_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2082\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_fsdp_xla_v2_enabled:\n\u001b[1;32m   2083\u001b[0m     train_dataloader \u001b[38;5;241m=\u001b[39m tpu_spmd_dataloader(train_dataloader)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/trainer.py:930\u001b[0m, in \u001b[0;36mTrainer.get_train_dataloader\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    927\u001b[0m     dataloader_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworker_init_fn\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m seed_worker\n\u001b[1;32m    928\u001b[0m     dataloader_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprefetch_factor\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdataloader_prefetch_factor\n\u001b[0;32m--> 930\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDataLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdataloader_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/accelerate/accelerator.py:1305\u001b[0m, in \u001b[0;36mAccelerator.prepare\u001b[0;34m(self, device_placement, *args)\u001b[0m\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1295\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(obj, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule)\n\u001b[1;32m   1296\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverify_device_map(obj)\n\u001b[1;32m   1297\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mNO\n\u001b[1;32m   1298\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mACCELERATE_BYPASS_DEVICE_MAP\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfalse\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1299\u001b[0m     ):\n\u001b[1;32m   1300\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1301\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt train a model that has been loaded with `device_map=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m` in any distributed mode.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1302\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Please rerun your script specifying `--num_processes=1` or by launching with `python \u001b[39m\u001b[38;5;124m{{\u001b[39m\u001b[38;5;124mmyscript.py}}`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1303\u001b[0m         )\n\u001b[0;32m-> 1305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistributed_type\u001b[49m \u001b[38;5;241m==\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED:\n\u001b[1;32m   1306\u001b[0m     model_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1307\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m args:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/accelerate/accelerator.py:579\u001b[0m, in \u001b[0;36mAccelerator.distributed_type\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdistributed_type\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 579\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistributed_type\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/accelerate/state.py:1125\u001b[0m, in \u001b[0;36mAcceleratorState.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;66;03m# By this point we know that no attributes of `self` contain `name`,\u001b[39;00m\n\u001b[1;32m   1123\u001b[0m     \u001b[38;5;66;03m# so we just modify the error message\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_known_attrs:\n\u001b[0;32m-> 1125\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1126\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`AcceleratorState` object has no attribute `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1127\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis happens if `AcceleratorState._reset_state()` was called and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1128\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man `Accelerator` or `PartialState` was not reinitialized.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1129\u001b[0m         )\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;66;03m# Raise a typical AttributeError\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAcceleratorState\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: `AcceleratorState` object has no attribute `distributed_type`. This happens if `AcceleratorState._reset_state()` was called and an `Accelerator` or `PartialState` was not reinitialized."
     ]
    }
   ],
   "source": [
    "# running the big boy\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample JSON-like data (you'll replace this with your CSV data)\n",
    "json_data = [\n",
    "    {\"entityType\": \"CDR\", \"relationTargetType\": \"Phone\"},\n",
    "    {\"entityType\": \"Report\", \"relationTargetType\": \"Malware\"}\n",
    "]\n",
    "\n",
    "# Example query from the user\n",
    "query = \"What SMS messages were sent from suspicious phones to 0549876543 containing 'urgent'?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to search for relevant entitties in teh JSON data\n",
    "def find_matching_entities(query, json_data):\n",
    "    matching_entities = []\n",
    "\n",
    "    for record in json_data:\n",
    "        entity_text = f\"{record['entityType']} {record['relationTargetType']}\"\n",
    "\n",
    "        #encode inputs for model\n",
    "        inputs = tokenizer(query, entity_text, return_tensors=\"pt\")\n",
    "\n",
    "        #run the model to get answer scores\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        #get the start and end scores for the answer\n",
    "        answer_start = torch.argmax(outputs.start_logits)\n",
    "        answer_end = torch.argmax(outputs.end_logits) + 1\n",
    "\n",
    "        #extract the answer\n",
    "        predicted_entity = tokenizer.convert_tokens_to_string(\n",
    "            tokenizer.convert_ids_to_tokens(inputs['input_ids'][0][answer_start:answer_end])\n",
    "        )\n",
    "\n",
    "        #if predicted entity is not empty, consider it a match\n",
    "        if predicted_entity.strip():\n",
    "            return record['entityType'], record['relationTargetType']\n",
    "\n",
    "    return None\n",
    "    # return list(set(matching_entities)) #remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Phone', 'CDR']\n"
     ]
    }
   ],
   "source": [
    "#Test example\n",
    "matching_entities = list(set(find_matching_entities(query, json_data)))\n",
    "print(matching_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
